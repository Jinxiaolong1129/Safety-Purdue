# Awesome-LM-SSP-Purdue

Thanks for Awesome-LM-SSP!

## Introduction 
The resources related to the trustworthiness of large models (LMs) across multiple dimensions (e.g., safety, security, and privacy),                  with a special focus on multi-modal LMs (e.g., vision-language models and diffusion models). 

<!-- - This repo is in progress :seedling: (currently manually collected). -->
- Badges: 

    - Model:
        - ![LLM](https://img.shields.io/badge/LLM_(Large_Language_Model)-589cf4)
        - ![VLM](https://img.shields.io/badge/VLM_(Vision_Language_Model)-c7688b) 
        - ![SLM](https://img.shields.io/badge/SLM_(Speech_Language_Model)-39c5bb) 
        - ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)

    - Comment: ![Benchmark](https://img.shields.io/badge/Benchmark-87b800) ![New_dataset](https://img.shields.io/badge/New_dataset-87b800) ![Agent](https://img.shields.io/badge/Agent-87b800)                 ![CodeGen](https://img.shields.io/badge/CodeGen-87b800) ![Defense](https://img.shields.io/badge/Defense-87b800) ![RAG](https://img.shields.io/badge/RAG-87b800) ![Chinese](https://img.shields.io/badge/Chinese-87b800) ...

   - Venue: ![conference](https://img.shields.io/badge/conference-f1b800) ![blog](https://img.shields.io/badge/blog-f1b800) ![OpenAI](https://img.shields.io/badge/OpenAI-f1b800)  ![Meta AI](https://img.shields.io/badge/Meta_AI-f1b800) ...


## News
- [2024.08.17] We collected `34` related papers from [ACL'24](https://2024.aclweb.org/)!
- [2024.05.13] We collected `7` related papers from [S&P'24](https://www.computer.org/csdl/proceedings/sp/2024/1RjE8VKKk1y)!
- [2024.04.27] We adjusted the categories.
- [2024.01.20] We collected `3` related papers from [NDSS'24](https://www.ndss-symposium.org/ndss2024/accepted-papers/)!
- [2024.01.17] We collected `108` related papers from [ICLR'24](https://openreview.net/group?id=ICLR.cc/2024/Conference)!


## Random Thoughts

- Multi agent system(abnormal detection, pruning, distill)
  - control permission(Claude agent)
- Physical LLM
  - Embodied AI (LLM on robot)
- Copyright
- Prompt injection



## Collections
- [Book](collection/book.md) (2)
- [Competition](collection/competition.md) (5)
- [Leaderboard](collection/leaderboard.md) (3)
- [Toolkit](collection/toolkit.md) (9)
- [Survey](collection/survey.md) (32)
- Paper (1140)
    - A. Safety (644)
        - [A0. General](collection/paper/safety/general.md) (15)
        - [A1. Jailbreak](collection/paper/safety/jailbreak.md) (246)
        - [A2. Alignment](collection/paper/safety/alignment.md) (71)
        - [A3. Deepfake](collection/paper/safety/deepfake.md) (53)
        - [A4. Ethics](collection/paper/safety/ethics.md) (5)
        - [A5. Fairness](collection/paper/safety/fairness.md) (54)
        - [A6. Hallucination](collection/paper/safety/hallucination.md) (106)
        - [A7. Prompt Injection](collection/paper/safety/prompt_injection.md) (29)
        - [A8. Toxicity](collection/paper/safety/toxicity.md) (65)
    - B. Security (178)
        - [B0. General](collection/paper/security/general.md) (6)
        - [B1. Adversarial Examples](collection/paper/security/adversarial_examples.md) (78)
        - [B2. Poison & Backdoor](collection/paper/security/poison_&_backdoor.md) (84)
        - [B3. System](collection/paper/security/system.md) (10)
    - C. Privacy (318)
        - [C0. General](collection/paper/privacy/general.md) (24)
        - [C1. Contamination](collection/paper/privacy/contamination.md) (13)
        - [C2. Copyright](collection/paper/privacy/copyright.md) (106)
        - [C3. Data Reconstruction](collection/paper/privacy/data_reconstruction.md) (35)
        - [C4. Membership Inference Attacks](collection/paper/privacy/membership_inference_attacks.md) (29)
        - [C5. Model Extraction](collection/paper/privacy/model_extraction.md) (10)
        - [C6. Privacy-Preserving Computation](collection/paper/privacy/privacy-preserving_computation.md) (54)
        - [C7. Property Inference Attacks](collection/paper/privacy/property_inference_attacks.md) (3)
        - [C8. Unlearning](collection/paper/privacy/unlearning.md) (44)
