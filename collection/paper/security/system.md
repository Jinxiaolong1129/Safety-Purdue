# B3. System
- [2024/10] **[Safeguard is a Double-edged Sword: Denial-of-service Attack on Large Language Models](https://arxiv.org/abs/2410.02916)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/09] **[The Early Bird Catches the Leak: Unveiling Timing Side Channels in LLM Serving Systems](https://arxiv.org/abs/2409.20002)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/05] **[Exploiting LLM Quantization](https://arxiv.org/abs/2405.18137)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/04] **[Attacks on Third-Party APIs of Large Language Models](https://arxiv.org/abs/2404.16891)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/04] **[Towards AI Safety: A Taxonomy for AI System Evaluation](https://arxiv.org/html/2404.05388v1)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/03] **[What Was Your Prompt? A Remote Keylogging Attack on AI Assistants](https://arxiv.org/abs/2403.09751)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/03] **[SecGPT: An Execution Isolation Architecture for LLM-Based Systems](https://arxiv.org/abs/2403.04960)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/03] **[Here Comes The AI Worm: Unleashing Zero-click Worms that Target GenAI-Powered Applications](https://arxiv.org/abs/2403.02817)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/02] **[A New Era in LLM Security: Exploring Security Concerns in Real-World LLM-based Systems](https://arxiv.org/abs/2402.18649)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/02] **[A First Look at GPT Apps: Landscape and Vulnerability](https://arxiv.org/abs/2402.15105)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![Apps](https://img.shields.io/badge/Apps-87b800)
