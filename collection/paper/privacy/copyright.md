# C2. Copyright

> related to watermark
## Diffusion
- [2024/10] **[An undetectable watermark for generative image models ](https://arxiv.org/abs/2410.07369)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2024/09] **[Towards Effective User Attribution for Latent Diffusion Models via Watermark-Informed Blending](https://arxiv.org/abs/2409.10958)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2024/09] **[Dormant: Defending against Pose-driven Human Image Animation](https://arxiv.org/abs/2409.14424)** [<img src="https://github.com/FortAwesome/Font-Awesome/blob/6.x/svgs/brands/github.svg" alt="Code" width="15" height="15">](https://github.com/Manu21JC/Dormant) ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2024/08] **[Robustness of Watermarking on Text-to-Image Diffusion Models ](https://arxiv.org/abs/2408.02035)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2024/06] **[AIGC-Chain: A Blockchain-Enabled Full Lifecycle Recording System for AIGC Product Copyright Management](https://arxiv.org/abs/2406.14966)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4) ![Blockchain](https://img.shields.io/badge/Blockchain-87b800)
- [2024/06] **[PID: Prompt-Independent Data Protection Against Latent Diffusion Models](https://arxiv.org/abs/2406.15305)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4) ![ICML'24](https://img.shields.io/badge/ICML'24-f1b800)
- [2024/06] **[EnTruth: Enhancing the Traceability of Unauthorized Dataset Usage in Text-to-image Diffusion Models with Minimal and Robust Alterations](https://arxiv.org/abs/2406.13933)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2024/06] **[Adversarial Perturbations Cannot Reliably Protect Artists From Generative AI](https://arxiv.org/abs/2406.12027)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2024/05] **[FreezeAsGuard: Mitigating Illegal Adaptation of Diffusion Models via Selective Tensor Freezing](https://arxiv.org/abs/2405.17472)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2024/05] **[AquaLoRA: Toward White-box Protection for Customized Stable Diffusion Models via Watermark LoRA](https://arxiv.org/abs/2405.11135)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2024/05] **[UnMarker: A Universal Attack on Defensive Watermarking](https://arxiv.org/abs/2405.08363)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2024/05] **[Stable Signature is Unstable: Removing Image Watermark from Diffusion Models](https://arxiv.org/abs/2405.07145)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2024/05] **[DiffuseTrace: A Transparent and Flexible Watermarking Scheme for Latent Diffusion Model](https://arxiv.org/abs/2405.02696)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2024/05] **[Lazy Layers to Make Fine-Tuned Diffusion Models More Traceable](https://arxiv.org/abs/2405.00466)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2024/04] **[Disguised Copyright Infringement of Latent Diffusion Model](https://arxiv.org/abs/2404.06737)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2024/04] **[Gaussian Shading: Provable Performance-Lossless Image Watermarking for Diffusion Models](https://arxiv.org/abs/2404.04956)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4) ![CVPR'24](https://img.shields.io/badge/CVPR'24-f1b800)
- [2024/04] **[A Training-Free Plug-and-Play Watermark Framework for Stable Diffusion](https://arxiv.org/abs/2404.05607)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2024/03] **[RAW: A Robust and Agile Plug-and-Play Watermark Framework for AI-Generated Images with Provable Guarantees](https://arxiv.org/abs/2403.18774)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2024/02] **[Generative Models are Self-Watermarked: Declaring Model Authentication through Re-Generation](https://arxiv.org/abs/2402.16889)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2024/03] **[A Transfer Attack to Image Watermarks](https://arxiv.org/abs/2403.15365)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2024/03] **[A Watermark-Conditioned Diffusion Model for IP Protection](https://arxiv.org/abs/2403.10893)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)


- [2024/02] **[Copyright Protection in Generative AI: A Technical Perspective ](https://arxiv.org/abs/2402.02333)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)

- [2024/01] **[Generative AI Has a Visual Plagiarism Problem](https://spectrum.ieee.org/midjourney-copyright)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4) ![Blog](https://img.shields.io/badge/Blog-f1b800)

- [2023/06] **[Generative Watermarking Against Unauthorized Subject-Driven Image Synthesis](https://arxiv.org/abs/2306.07754)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2023/05] **[Tree-Ring Watermarks: Fingerprints for Diffusion Images that are Invisible and Robust](https://arxiv.org/abs/2305.20030)** [<img src="https://github.com/FortAwesome/Font-Awesome/blob/6.x/svgs/brands/github.svg" alt="Code" width="15" height="15">](https://github.com/YuxinWenRick/tree-ring-watermark) ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4) ![NeurIPS'23](https://img.shields.io/badge/NeurIPS'23-f1b800)
- [2023/05] **[Watermarking Diffusion Model](https://arxiv.org/abs/2305.12502)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2023/03] **[A Recipe for Watermarking Diffusion Models](https://arxiv.org/abs/2303.10137)** [<img src="https://github.com/FortAwesome/Font-Awesome/blob/6.x/svgs/brands/github.svg" alt="Code" width="15" height="15">](https://github.com/yunqing-me/WatermarkDM) ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)




## LLM
- [2024/10] **[UTF:Undertrained Tokens as Fingerprints A Novel Approach to LLM Identification](https://arxiv.org/abs/2410.12318)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/10] **[FreqMark: Frequency-Based Watermark for Sentence-Level Detection of LLM-Generated Text](https://arxiv.org/abs/2410.10876)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/10] **[MergePrint: Robust Fingerprinting against Merging Large Language Models](https://arxiv.org/abs/2410.08604)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/10] **[WAPITI: A Watermark for Finetuned Open-Source LLMs](https://arxiv.org/abs/2410.06467)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/10] **[Signal Watermark on Large Language Models](https://arxiv.org/abs/2410.06545)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/10] **[Ward: Provable RAG Dataset Inference via LLM Watermarks](https://arxiv.org/abs/2410.03537)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![RAG](https://img.shields.io/badge/RAG-87b800)
- [2024/10] **[Universally Optimal Watermarking Schemes for LLMs: from Theory to Practice](https://arxiv.org/abs/2410.02890)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/10] **[Can Watermarked LLMs be Identified by Users via Crafted Prompts?](https://arxiv.org/abs/2410.03168)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/10] **[A Watermark for Black-Box Language Models](https://arxiv.org/abs/2410.02099)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/10] **[Optimizing Adaptive Attacks against Content Watermarks for Language Models](https://arxiv.org/abs/2410.02440)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/10] **[Discovering Clues of Spoofed LM Watermarks](https://arxiv.org/abs/2410.02693)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/09] **[A Certified Robust Watermark For Large Language Models](https://arxiv.org/abs/2409.19708)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/09] **[Multi-Designated Detector Watermarking for Language Models](https://arxiv.org/abs/2409.17518)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/09] **[Measuring Copyright Risks of Large Language Model via Partial Information Probing](https://arxiv.org/abs/2409.13831)** ![LLM](https://img.shields.io/badge/LLM-589cf4)

- [2024/09] **[PersonaMark: Personalized LLM watermarking for model protection and user attribution](https://arxiv.org/abs/2409.09739)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/09] **[FP-VEC: Fingerprinting Large Language Models via Efficient Vector Addition](https://arxiv.org/abs/2409.08846)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/08] **[Watermarking Techniques for Large Language Models: A Survey](https://arxiv.org/abs/2409.00089)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![Survey](https://img.shields.io/badge/Survey-87b800)
- [2024/08] **[MCGMark: An Encodable and Robust Online Watermark for LLM-Generated Malicious Code](https://arxiv.org/abs/2408.01354)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![codeGen](https://img.shields.io/badge/codeGen-87b800)
- [2024/08] **[Hide and Seek: Fingerprinting Large Language Models with Evolutionary Learning](https://arxiv.org/abs/2408.02871)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/07] **[Strong Copyright Protection for Language Models via Adaptive Model Fusion](https://arxiv.org/abs/2407.20105)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/07] **[LLMmap: Fingerprinting For Large Language Models](https://arxiv.org/abs/2407.15847)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/07] **[SLIP: Securing LLMs IP Using Weights Decomposition](https://arxiv.org/abs/2407.10886)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/07] **[Hey, That's My Model! Introducing Chain & Hash, An LLM Fingerprinting Technique](https://arxiv.org/abs/2407.10887)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/07] **[Building Intelligence Identification System via Large Language Model Watermarking: A Survey and Beyond](https://arxiv.org/abs/2407.11100)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/07] **[Less is More: Sparse Watermarking in LLMs with Enhanced Text Quality](https://arxiv.org/abs/2407.13803)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/07] **[On Evaluating The Performance of Watermarked Machine-Generated Texts Under Adversarial Attacks](https://arxiv.org/abs/2407.04794)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/07] **[Waterfall: Framework for Robust and Scalable Text Watermarking](https://arxiv.org/abs/2407.04411)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/07] **[A Fingerprint for Large Language Models](https://arxiv.org/abs/2407.01235)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/06] **[PostMark: A Robust Blackbox Watermark for Large Language Models](https://arxiv.org/abs/2406.14517)** ![LLM](https://img.shields.io/badge/LLM-589cf4)

- [2024/06] **[Hiding Text in Large Language Models: Introducing Unconditional Token Forcing Confusion](https://arxiv.org/abs/2406.02481)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/06] **[Bileve: Securing Text Provenance in Large Language Models Against Spoofing with Bi-level Signature](https://arxiv.org/abs/2406.01946)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/06] **[Edit Distance Robust Watermarks for Language Models](https://arxiv.org/abs/2406.02633)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/05] **[Black-Box Detection of Language Model Watermarks](https://arxiv.org/abs/2405.20777)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/05] **[Large Language Model Watermark Stealing With Mixed Integer Programming](https://arxiv.org/abs/2405.19677)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/05] **[A Watermark for Low-entropy and Unbiased Generation in Large Language Models](https://arxiv.org/abs/2405.14604)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/05] **[Enhancing Watermarked Language Models to Identify Users](https://arxiv.org/abs/2405.11109)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/05] **[Stylometric Watermarks for Large Language Models](https://arxiv.org/abs/2405.08400)** ![LLM](https://img.shields.io/badge/LLM-589cf4)

- [2024/05] **[Adaptive and robust watermark against model extraction attack](https://arxiv.org/abs/2405.02365)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/05] **[ProFLingo: A Fingerprinting-based Copyright Protection Scheme for Large Language Models](https://arxiv.org/abs/2405.02466)** ![LLM](https://img.shields.io/badge/LLM-589cf4)

- [2024/04] **[Have You Merged My Model? On The Robustness of Large Language Model IP Protection Methods Against Model Merging](https://arxiv.org/abs/2404.05188)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![LAMPS@CCS‘24](https://img.shields.io/badge/LAMPS@CCS‘24-f1b800) ![Best Paper](https://img.shields.io/badge/Best_paper-ff0000)
- [2024/04] **[Topic-based Watermarks for LLM-Generated Text](https://arxiv.org/abs/2404.02138)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/04] **[A Statistical Framework of Watermarks for Large Language Models: Pivot, Detection Efficiency and Optimal Rules](https://arxiv.org/abs/2404.01245)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/03] **[Is Watermarking LLM-Generated Code Robust?](https://arxiv.org/abs/2403.17983)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![codeGen](https://img.shields.io/badge/codeGen-87b800)
- [2024/03] **[Ghost Sentence: A Tool for Everyday Users to Copyright Data from Large Language Models](https://arxiv.org/abs/2403.15740)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/03] **[Bypassing LLM Watermarks with Color-Aware Substitutions](https://arxiv.org/abs/2403.14719)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/03] **[An Entropy-based Text Watermarking Detection Method](https://arxiv.org/abs/2403.13485)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/03] **[Duwak: Dual Watermarks in Large Language Models](https://arxiv.org/abs/2403.13000)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/03] **[Towards Better Statistical Understanding of Watermarking LLMs](https://arxiv.org/abs/2403.13027)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/03] **[Learning to Watermark LLM-generated Text via Reinforcement Learning](https://arxiv.org/abs/2403.10553)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/03] **[Hufu: A Modality-Agnositc Watermarking System for Pre-Trained Transformers via Permutation Equivariance](https://arxiv.org/abs/2403.05842)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/03] **[WaterMax: breaking the LLM watermark detectability-robustness-quality trade-off](https://arxiv.org/abs/2403.04808)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/02] **[Watermark Stealing in Large Language Models](https://arxiv.org/abs/2402.19361)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/02] **[Token-Specific Watermarking with Enhanced Detectability and Semantic Coherence for Large Language Models](https://arxiv.org/abs/2402.18059)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/02] **[EmMark: Robust Watermarks for IP Protection of Embedded Quantized Large Language Models](https://arxiv.org/abs/2402.17938)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/02] **[Attacking LLM Watermarks by Exploiting Their Strengths](https://arxiv.org/abs/2402.16187)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/02] **[Double-I Watermark: Protecting Model Copyright for LLM Fine-tuning](https://arxiv.org/abs/2402.14883)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![Defense](https://img.shields.io/badge/Defense-87b800)
- [2024/02] **[Watermarking Makes Language Models Radioactive](https://arxiv.org/abs/2402.14904)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![Defense](https://img.shields.io/badge/Defense-87b800)
- [2024/02] **[Can Watermarks Survive Translation? On the Cross-lingual Consistency of Text Watermark for Large Language Models](https://arxiv.org/abs/2402.14007)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/02] **[A Survey of Text Watermarking in the Era of Large Language Models](https://arxiv.org/abs/2312.07913)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![Survey](https://img.shields.io/badge/Survey-87b800)
- [2024/02] **[Proving membership in LLM pretraining data via data watermarks](https://arxiv.org/abs/2402.10892)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![Defense](https://img.shields.io/badge/Defense-87b800)
- [2024/02] **[Resilient Watermarking for LLM-Generated Codes](https://arxiv.org/abs/2402.07518)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![Defense](https://img.shields.io/badge/Defense-87b800)
- [2024/02] **[Permute-and-Flip: An optimally robust and watermarkable decoder for LLMs](https://arxiv.org/abs/2402.05864)** [<img src="https://github.com/FortAwesome/Font-Awesome/blob/6.x/svgs/brands/github.svg" alt="Code" width="15" height="15">](https://github.com/XuandongZhao/pf-decoding) ![LLM](https://img.shields.io/badge/LLM-589cf4) ![Defense](https://img.shields.io/badge/Defense-87b800)
- [2024/01] **[Adaptive Text Watermark for Large Language Models](https://arxiv.org/abs/2401.13927)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/01] **[Instructional Fingerprinting of Large Language Models](https://arxiv.org/abs/2401.12255)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2023/12] **[Human-Readable Fingerprint for Large Language Models](https://arxiv.org/abs/2312.04828)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2023/12] **[Mark My Words: Analyzing and Evaluating Language Model Watermarks](https://arxiv.org/abs/2312.00273)** [<img src="https://github.com/FortAwesome/Font-Awesome/blob/6.x/svgs/brands/github.svg" alt="Code" width="15" height="15">](https://github.com/wagner-group/MarkMyWords) ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2023/11] **[WaterBench: Towards Holistic Evaluation of Watermarks for Large Language Models](https://arxiv.org/abs/2311.07138)** [<img src="https://github.com/FortAwesome/Font-Awesome/blob/6.x/svgs/brands/github.svg" alt="Code" width="15" height="15">](https://github.com/THU-KEG/WaterBench) ![LLM](https://img.shields.io/badge/LLM-589cf4) ![ACL'24](https://img.shields.io/badge/ACL'24-f1b800)
- [2023/11] **[Towards More Effective Protection Against Diffusion-Based Mimicry with Score Distillation](https://arxiv.org/abs/2311.12832)** [<img src="https://github.com/FortAwesome/Font-Awesome/blob/6.x/svgs/brands/github.svg" alt="Code" width="15" height="15">](https://github.com/xavihart/Diff-Protect) ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4) ![ICLR'24](https://img.shields.io/badge/ICLR'24-f1b800)
- [2023/11] **[A Robust Semantics-based Watermark for Large Language Model against Paraphrasing](https://arxiv.org/abs/2311.08721)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2023/11] **[Protecting Intellectual Property of Large Language Model-Based Code Generation APIs via Watermarks](https://dl.acm.org/doi/abs/10.1145/3576915.3623120)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![CodeGen](https://img.shields.io/badge/CodeGen-87b800) ![CCS'23](https://img.shields.io/badge/CCS'23-f1b800)
- [2023/10] **[REMARK-LLM: A Robust and Efficient Watermarking Framework for Generative Large Language Models ](https://arxiv.org/abs/2310.12362)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![USENIX_Security'24](https://img.shields.io/badge/USENIX_Security'24-f1b800)
- [2023/10] **[Watermarking LLMs with Weight Quantization](https://arxiv.org/abs/2310.11237)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![EMNLP‘23_(Findings)](https://img.shields.io/badge/EMNLP‘23_(Findings)-f1b800)
- [2023/09] **[A Private Watermark for Large Language Models](https://openreview.net/forum?id=gMLQwKDY3N)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![ICLR'24](https://img.shields.io/badge/ICLR'24-f1b800)
- [2023/09] **[A Semantic Invariant Robust Watermark for Large Language Models](https://openreview.net/forum?id=6p8lpe4MNf)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![ICLR'24](https://img.shields.io/badge/ICLR'24-f1b800)
- [2023/09] **[Provable Robust Watermarking for AI-Generated Text](https://openreview.net/forum?id=SsmT8aO45L)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![ICLR'24](https://img.shields.io/badge/ICLR'24-f1b800)
- [2023/09] **[SILO Language Models: Isolating Legal Risk In a Nonparametric Datastore](https://openreview.net/forum?id=ruk0nyQPec)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![ICLR'24_(Spotlight)](https://img.shields.io/badge/ICLR'24_(Spotlight)-f1b800)
- [2023/08] **[PromptCARE: Prompt Copyright Protection by Watermark Injection and Verification](https://arxiv.org/abs/2308.02816)** [<img src="https://github.com/FortAwesome/Font-Awesome/blob/6.x/svgs/brands/github.svg" alt="Code" width="15" height="15">](https://github.com/grasses/PromptCARE) ![LLM](https://img.shields.io/badge/LLM-589cf4) ![S&P'24](https://img.shields.io/badge/S&P'24-f1b800)

- [2023/02] **[Glaze: Protecting Artists from Style Mimicry by Text-to-Image Models](https://arxiv.org/abs/2302.04222)** [<img src="https://github.com/FortAwesome/Font-Awesome/blob/6.x/svgs/brands/github.svg" alt="Code" width="15" height="15">](https://glaze.cs.uchicago.edu/) ![LLM](https://img.shields.io/badge/LLM-589cf4) ![USENIX_Security'23](https://img.shields.io/badge/USENIX_Security'23-f1b800) ![Best Paper](https://img.shields.io/badge/Best_paper-ff0000)
- [2023/01] **[A Watermark for Large Language Models](https://arxiv.org/abs/2301.10226)** [<img src="https://github.com/FortAwesome/Font-Awesome/blob/6.x/svgs/brands/github.svg" alt="Code" width="15" height="15">](github.com/jwkirchenbauer/lm-watermarking) ![LLM](https://img.shields.io/badge/LLM-589cf4) ![ICML'23](https://img.shields.io/badge/ICML'23-f1b800) ![Best Paper](https://img.shields.io/badge/Best_paper-ff0000)
