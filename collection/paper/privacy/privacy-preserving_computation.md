# C6. Privacy-Preserving Computation
- [2024/10] **[Rescriber: Smaller-LLM-Powered User-Led Data Minimization for Navigating Privacy Trade-offs in LLM-Based Conversational Agent](https://arxiv.org/abs/2410.11876)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/10] **[Data-adaptive Differentially Private Prompt Synthesis for In-Context Learning](https://arxiv.org/abs/2410.12085)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/10] **[Reconstruction of Differentially Private Text Sanitization via Large Language Models](https://arxiv.org/abs/2410.12443)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/10] **[Privately Learning from Graphs with Applications in Fine-tuning Large Language Models](https://arxiv.org/abs/2410.08299)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/10] **[Fine-Tuning Language Models with Differential Privacy through Adaptive Noise Allocation](https://arxiv.org/abs/2410.02912)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/10] **[Adaptively Private Next-Token Prediction of Large Language Models](https://arxiv.org/abs/2410.02016)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/10] **[Encryption-Friendly LLM Architecture](https://arxiv.org/abs/2410.02486)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/10] **[PrivTuner with Homomorphic Encryption and LoRA: A P3EFT Scheme for Privacy-Preserving Parameter-Efficient Fine-Tuning of AI Foundation Models](https://arxiv.org/abs/2410.00433)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/09] **[Secure Multiparty Generative AI](https://arxiv.org/abs/2409.19120)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/09] **[Confidential Prompting: Protecting User Prompts from Cloud LLM Providers](https://arxiv.org/abs/2409.19134)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/08] **[Learning Differentially Private Diffusion Models via Stochastic Adversarial Distillation](https://arxiv.org/abs/2408.14738)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2024/08] **[SecFormer: Fast and Accurate Privacy-Preserving Inference for Transformer Models via SMPC](https://aclanthology.org/2024.findings-acl.790/)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![ACL'24_(Findings)](https://img.shields.io/badge/ACL'24_(Findings)-f1b800)
- [2024/08] **[Towards Privacy-Aware Sign Language Translation at Scale](https://aclanthology.org/2024.acl-long.467/)** ![VLM](https://img.shields.io/badge/VLM-c7688b) ![ACL'24](https://img.shields.io/badge/ACL'24-f1b800)
- [2024/08] **[Casper: Prompt Sanitization for Protecting User Privacy in Web-Based Large Language Models](https://arxiv.org/abs/2408.07004)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/08] **[MPC-Minimized Secure LLM Inference](https://arxiv.org/abs/2408.03561)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/07] **[Fine-Tuning Large Language Models with User-Level Differential Privacy](https://arxiv.org/abs/2407.07737)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/07] **[IncogniText: Privacy-enhancing Conditional Text Anonymization via LLM-based Private Attribute Randomization](https://arxiv.org/abs/2407.02956)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/07] **[ObfuscaTune: Obfuscated Offsite Fine-tuning and Inference of Proprietary LLMs on Private Datasets](https://arxiv.org/abs/2407.02960)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/06] **[Safely Learning with Private Data: A Federated Learning Framework for Large Language Model](https://arxiv.org/abs/2406.14898)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/06] **[Mind the Privacy Unit! User-Level Differential Privacy for Language Model Fine-Tuning](https://arxiv.org/abs/2406.14322)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/06] **[The Fire Thief Is Also the Keeper: Balancing Usability and Privacy in Prompts](https://arxiv.org/abs/2406.14318)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/06] **[Promoting Data and Model Privacy in Federated Learning through Quantized LoRA](https://arxiv.org/abs/2406.10976)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/06] **[MemDPT: Differential Privacy for Memory Efficient Language Models](https://arxiv.org/abs/2406.11087)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/06] **[Efficient Differentially Private Fine-Tuning of Diffusion Models](https://arxiv.org/abs/2406.05257)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2024/06] **[PrE-Text: Training Language Models on Private Federated Data in the Age of LLMs](https://arxiv.org/abs/2406.02958)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/06] **[Differentially Private Fine-Tuning of Diffusion Models](https://arxiv.org/abs/2406.01355)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2024/06] **[PrivacyRestore: Privacy-Preserving Inference in Large Language Models via Privacy Removal and Restoration](https://arxiv.org/abs/2406.01394)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/05] **[No Free Lunch Theorem for Privacy-Preserving LLM Inference](https://arxiv.org/abs/2405.20681)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/05] **[PermLLM: Private Inference of Large Language Models within 3 Seconds under WAN](https://arxiv.org/abs/2405.18744)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/05] **[LMO-DP: Optimizing the Randomization Mechanism for Differentially Private Fine-Tuning (Large) Language Models](https://arxiv.org/abs/2405.18776)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/05] **[Delving into Differentially Private Transformer](https://arxiv.org/abs/2405.18194)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![ICML'24](https://img.shields.io/badge/ICML'24-f1b800)
- [2024/05] **[Locally Differentially Private In-Context Learning](https://arxiv.org/abs/2405.04032)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![LREC-Coling’24](https://img.shields.io/badge/LREC-Coling’24-f1b800)
- [2024/04] **[zkLLM: Zero Knowledge Proofs for Large Language Models](https://arxiv.org/abs/2404.16109)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![CCS'24](https://img.shields.io/badge/CCS'24-f1b800)
- [2024/03] **[Efficient Language Model Architectures for Differentially Private Federated Learning](https://arxiv.org/abs/2403.08100)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/03] **[A Framework for Cost-Effective and Self-Adaptive LLM Shaking and Recovery Mechanism](https://arxiv.org/abs/2403.07283)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/03] **[DP-TabICL: In-Context Learning with Differentially Private Tabular Data](https://arxiv.org/abs/2403.05681)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/03] **[Privacy-Preserving Diffusion Model Using Homomorphic Encryption](https://arxiv.org/abs/2403.05794)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2024/02] **[LLM-based Privacy Data Augmentation Guided by Knowledge Distillation with a Distribution Tutor for Medical Text Classification](https://arxiv.org/abs/2402.16515)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/02] **[Privacy-Preserving Language Model Inference with Instance Obfuscation](https://arxiv.org/abs/2402.08227)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![Defense](https://img.shields.io/badge/Defense-87b800)
- [2024/02] **[PromptCrypt: Prompt Encryption for Secure Communication with Large Language Models](https://arxiv.org/abs/2402.05868)** [<img src="https://github.com/FortAwesome/Font-Awesome/blob/6.x/svgs/brands/github.svg" alt="Code" width="15" height="15">](https://github.com/agiresearch/PromptCrypt) ![LLM](https://img.shields.io/badge/LLM-589cf4) ![Defense](https://img.shields.io/badge/Defense-87b800)
- [2023/10] **[Locally Differentially Private Document Generation Using Zero Shot Prompting](https://arxiv.org/abs/2310.16111)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![EMNLP'23_(Findings)](https://img.shields.io/badge/EMNLP'23_(Findings)-f1b800)
- [2023/09] **[Differentially Private Synthetic Data via Foundation Model APIs 1: Images](https://openreview.net/forum?id=YEhQs8POIo)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4) ![ICLR'24](https://img.shields.io/badge/ICLR'24-f1b800)
- [2023/09] **[DP-OPT: Make Large Language Model Your Differentially-Private Prompt Engineer](https://openreview.net/forum?id=Ifz3IgsEPX)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![ICLR'24_(Spotlight)](https://img.shields.io/badge/ICLR'24_(Spotlight)-f1b800)
- [2023/09] **[Enhancing Small Medical Learners with Privacy-preserving Contextual Prompting](https://openreview.net/forum?id=ztpy1gsUpT)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![ICLR'24](https://img.shields.io/badge/ICLR'24-f1b800)
- [2023/09] **[Improving LoRA in Privacy-preserving Federated Learning](https://openreview.net/forum?id=NLPzL6HWNl)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![ICLR'24](https://img.shields.io/badge/ICLR'24-f1b800)
- [2023/09] **[Privacy-Preserving In-Context Learning for Large Language Models](https://openreview.net/forum?id=x4OPJ7lHVU)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![ICLR'24](https://img.shields.io/badge/ICLR'24-f1b800)
- [2023/09] **[Privacy-Preserving In-Context Learning with Differentially Private Few-Shot Generation](https://openreview.net/forum?id=oZtt0pRnOl)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![ICLR'24](https://img.shields.io/badge/ICLR'24-f1b800)
- [2023/09] **[Privately Aligning Language Models with Reinforcement Learning](https://openreview.net/forum?id=3d0OmYTNui)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![ICLR'24](https://img.shields.io/badge/ICLR'24-f1b800)
- [2023/09] **[DP-Forward: Fine-tuning and Inference on Language Models with Differential Privacy in Forward Pass](https://arxiv.org/abs/2309.06746)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![Defense](https://img.shields.io/badge/Defense-87b800) ![CCS'23](https://img.shields.io/badge/CCS'23-f1b800)
- [2023/08] **[SIGMA: Secure GPT Inference with Function Secret Sharing](https://eprint.iacr.org/2023/1269)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2023/07] **[CipherGPT: Secure Two-Party GPT Inference](https://eprint.iacr.org/2023/1147)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2023/05] **[Privacy-Preserving Prompt Tuning for Large Language Model Services](https://arxiv.org/abs/2305.06212)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2023/05] **[Privacy-Preserving Recommender Systems with Synthetic Query Generation using Differentially Private Large Language Models](https://arxiv.org/abs/2305.05973)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2022/10] **[EW-Tune: A Framework for Privately Fine-Tuning Large Language Models with Differential Privacy](https://arxiv.org/abs/2210.15042)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![ICDM'22_(Workshops)](https://img.shields.io/badge/ICDM'22_(Workshops)-f1b800)
